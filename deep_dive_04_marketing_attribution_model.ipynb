{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92accfae-a336-4a4a-956f-9c25cea0cc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 MARKETING ATTRIBUTION ANALYSIS\n",
      "============================================================\n",
      "📊 Creating sample data for attribution analysis...\n",
      "✅ Transaction data: 5000 purchases, $209,787 revenue\n",
      "\n",
      "🚀 Starting marketing attribution analysis...\n",
      "🔍 Simulating customer journey data...\n",
      "✅ Customer journey data simulated:\n",
      "  🎯 5000 converting journeys\n",
      "  📊 12332 non-converting journeys\n",
      "  📈 35181 total touchpoints\n",
      "\n",
      "🤖 Building attribution models...\n",
      "  🧠 Training ML attribution model...\n",
      "  📈 ML model AUC: 1.000\n",
      "✅ Attribution models built:\n",
      "  📊 First Touch: $209,787 attributed revenue\n",
      "  📊 Last Touch: $209,787 attributed revenue\n",
      "  📊 Linear: $209,787 attributed revenue\n",
      "  📊 Time Decay: $209,787 attributed revenue\n",
      "  📊 Ml Based: $209,787 attributed revenue\n",
      "\n",
      "📊 Calculating channel performance metrics...\n",
      "✅ Channel performance calculated:\n",
      "  🎯 8 channels analyzed\n",
      "  📊 Best ROAS: 999.99\n",
      "  💰 Total marketing spend: $49,901\n",
      "\n",
      "💰 Optimizing budget allocation...\n",
      "✅ Budget optimization completed:\n",
      "  💰 Total budget optimized: $100,000\n",
      "\n",
      "🎯 TOP BUDGET RECOMMENDATIONS:\n",
      "  1. Direct\n",
      "     📊 Change: +0% ($+13,444)\n",
      "     💰 Expected impact: $+67,220\n",
      "     💡 Maintain current investment level\n",
      "  2. Referral\n",
      "     📊 Change: +0% ($+13,146)\n",
      "     💰 Expected impact: $+65,732\n",
      "     💡 Maintain current investment level\n",
      "  3. Organic Search\n",
      "     📊 Change: +0% ($+12,922)\n",
      "     💰 Expected impact: $+64,609\n",
      "     💡 Maintain current investment level\n",
      "\n",
      "📊 Creating attribution analysis summary...\n",
      "\n",
      "✅ Marketing attribution analysis completed!\n",
      "🎯 35181 customer touchpoints analyzed\n",
      "📊 5 attribution models compared\n",
      "💰 Overall ROAS: 13.01x\n",
      "🏆 Best performing channel: Direct\n",
      "\n",
      "📈 ATTRIBUTION MODEL COMPARISON:\n",
      "  📊 First Touch: $209,786\n",
      "  📊 Last Touch: $209,788\n",
      "  📊 Linear: $209,787\n",
      "  📊 Ml Based: $209,787\n",
      "  📊 Time Decay: $209,787\n",
      "\n",
      "🎯 TOP CHANNEL PERFORMANCE:\n",
      "  1. Direct: ∞ ROAS, 43.5% conversion\n",
      "  2. Organic Search: ∞ ROAS, 42.6% conversion\n",
      "  3. Referral: ∞ ROAS, 41.5% conversion\n",
      "  4. Email Marketing: 112.3x ROAS, 63.2% conversion\n",
      "  5. Affiliate: 17.1x ROAS, 65.5% conversion\n",
      "\n",
      "💰 BUDGET OPTIMIZATION SUMMARY:\n",
      "  1. Direct: +0% change recommended\n",
      "  2. Referral: +0% change recommended\n",
      "  3. Organic Search: +0% change recommended\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"📈 MARKETING ATTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "class MarketingAttributionAnalyzer:\n",
    "    \"\"\"\n",
    "    Advanced marketing attribution modeling for e-commerce\n",
    "    Multi-touch attribution, channel optimization, and ROI analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, transaction_data):\n",
    "        self.transaction_data = transaction_data\n",
    "        self.customer_journeys = {}\n",
    "        self.attribution_models = {}\n",
    "        self.channel_performance = {}\n",
    "        \n",
    "    def simulate_customer_journeys(self):\n",
    "        \"\"\"Simulate realistic customer journey data with multiple touchpoints\"\"\"\n",
    "        \n",
    "        print(\"🔍 Simulating customer journey data...\")\n",
    "        \n",
    "        # Marketing channels with realistic properties\n",
    "        channels = {\n",
    "            'organic_search': {\n",
    "                'cost_per_click': 0.0,\n",
    "                'conversion_rate': 0.025,\n",
    "                'typical_position': 'first_touch',\n",
    "                'attribution_weight': 0.4\n",
    "            },\n",
    "            'paid_search': {\n",
    "                'cost_per_click': 2.50,\n",
    "                'conversion_rate': 0.045,\n",
    "                'typical_position': 'last_touch',\n",
    "                'attribution_weight': 0.25\n",
    "            },\n",
    "            'social_media': {\n",
    "                'cost_per_click': 1.80,\n",
    "                'conversion_rate': 0.018,\n",
    "                'typical_position': 'middle_touch',\n",
    "                'attribution_weight': 0.15\n",
    "            },\n",
    "            'email_marketing': {\n",
    "                'cost_per_click': 0.20,\n",
    "                'conversion_rate': 0.065,\n",
    "                'typical_position': 'last_touch',\n",
    "                'attribution_weight': 0.30\n",
    "            },\n",
    "            'display_ads': {\n",
    "                'cost_per_click': 3.20,\n",
    "                'conversion_rate': 0.012,\n",
    "                'typical_position': 'first_touch',\n",
    "                'attribution_weight': 0.10\n",
    "            },\n",
    "            'affiliate': {\n",
    "                'cost_per_click': 1.50,\n",
    "                'conversion_rate': 0.035,\n",
    "                'typical_position': 'last_touch',\n",
    "                'attribution_weight': 0.20\n",
    "            },\n",
    "            'direct': {\n",
    "                'cost_per_click': 0.0,\n",
    "                'conversion_rate': 0.080,\n",
    "                'typical_position': 'last_touch',\n",
    "                'attribution_weight': 0.35\n",
    "            },\n",
    "            'referral': {\n",
    "                'cost_per_click': 0.0,\n",
    "                'conversion_rate': 0.055,\n",
    "                'typical_position': 'middle_touch',\n",
    "                'attribution_weight': 0.25\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        customer_journeys = []\n",
    "        journey_id = 1\n",
    "        \n",
    "        for _, transaction in self.transaction_data.iterrows():\n",
    "            customer_id = transaction['customer_id']\n",
    "            purchase_date = pd.to_datetime(transaction['date'])\n",
    "            purchase_value = transaction['total_amount']\n",
    "            \n",
    "            # Simulate journey length (1-7 touchpoints)\n",
    "            journey_length = np.random.choice([1, 2, 3, 4, 5, 6, 7], \n",
    "                                            p=[0.25, 0.20, 0.18, 0.15, 0.10, 0.07, 0.05])\n",
    "            \n",
    "            # Generate touchpoints leading to purchase\n",
    "            touchpoints = []\n",
    "            journey_channels = []\n",
    "            \n",
    "            for touch_num in range(journey_length):\n",
    "                # Select channel based on position in journey - FIXED PROBABILITIES\n",
    "                if touch_num == 0:  # First touch\n",
    "                    channel_probs = [0.30, 0.15, 0.20, 0.05, 0.25, 0.02, 0.02, 0.01]\n",
    "                elif touch_num == journey_length - 1:  # Last touch\n",
    "                    channel_probs = [0.10, 0.25, 0.10, 0.30, 0.05, 0.15, 0.03, 0.02]\n",
    "                else:  # Middle touches\n",
    "                    channel_probs = [0.15, 0.20, 0.25, 0.15, 0.10, 0.10, 0.03, 0.02]\n",
    "                \n",
    "                # Normalize probabilities to ensure they sum to 1.0\n",
    "                channel_probs = np.array(channel_probs)\n",
    "                channel_probs = channel_probs / channel_probs.sum()\n",
    "                \n",
    "                channel = np.random.choice(list(channels.keys()), p=channel_probs)\n",
    "                journey_channels.append(channel)\n",
    "                \n",
    "                # Calculate touchpoint date (1-30 days before purchase)\n",
    "                days_before = np.random.exponential(scale=5) + touch_num * 2\n",
    "                days_before = min(days_before, 30)  # Cap at 30 days\n",
    "                touchpoint_date = purchase_date - timedelta(days=days_before)\n",
    "                \n",
    "                touchpoint = {\n",
    "                    'journey_id': journey_id,\n",
    "                    'customer_id': customer_id,\n",
    "                    'touchpoint_number': touch_num + 1,\n",
    "                    'channel': channel,\n",
    "                    'touchpoint_date': touchpoint_date,\n",
    "                    'purchase_date': purchase_date,\n",
    "                    'days_to_conversion': days_before,\n",
    "                    'conversion_value': purchase_value,\n",
    "                    'channel_cost': channels[channel]['cost_per_click'],\n",
    "                    'converted': 1\n",
    "                }\n",
    "                \n",
    "                touchpoints.append(touchpoint)\n",
    "            \n",
    "            # Add journey summary\n",
    "            journey_summary = {\n",
    "                'journey_id': journey_id,\n",
    "                'customer_id': customer_id,\n",
    "                'journey_length': journey_length,\n",
    "                'first_touch_channel': journey_channels[0],\n",
    "                'last_touch_channel': journey_channels[-1],\n",
    "                'journey_duration': max([t['days_to_conversion'] for t in touchpoints]),\n",
    "                'total_touchpoints': journey_length,\n",
    "                'unique_channels': len(set(journey_channels)),\n",
    "                'conversion_value': purchase_value,\n",
    "                'converted': 1\n",
    "            }\n",
    "            \n",
    "            customer_journeys.extend(touchpoints)\n",
    "            journey_id += 1\n",
    "        \n",
    "        # Create non-converting journeys (important for attribution modeling)\n",
    "        non_converting_journeys = []\n",
    "        for _ in range(int(len(customer_journeys) * 0.8)):  # 80% non-converting traffic\n",
    "            \n",
    "            journey_length = np.random.choice([1, 2, 3, 4], p=[0.60, 0.25, 0.10, 0.05])\n",
    "            customer_id = np.random.randint(1, 10000)  # New customer IDs\n",
    "            journey_date = pd.to_datetime(np.random.choice(self.transaction_data['date']))\n",
    "            \n",
    "            for touch_num in range(journey_length):\n",
    "                channel_probs = np.array([0.25, 0.15, 0.25, 0.10, 0.15, 0.05, 0.03, 0.02])\n",
    "                channel_probs = channel_probs / channel_probs.sum()  # Normalize\n",
    "                channel = np.random.choice(list(channels.keys()), p=channel_probs)\n",
    "                \n",
    "                days_before = np.random.exponential(scale=3) + touch_num\n",
    "                touchpoint_date = journey_date - timedelta(days=days_before)\n",
    "                \n",
    "                touchpoint = {\n",
    "                    'journey_id': journey_id,\n",
    "                    'customer_id': customer_id,\n",
    "                    'touchpoint_number': touch_num + 1,\n",
    "                    'channel': channel,\n",
    "                    'touchpoint_date': touchpoint_date,\n",
    "                    'purchase_date': None,\n",
    "                    'days_to_conversion': None,\n",
    "                    'conversion_value': 0,\n",
    "                    'channel_cost': channels[channel]['cost_per_click'],\n",
    "                    'converted': 0\n",
    "                }\n",
    "                \n",
    "                non_converting_journeys.append(touchpoint)\n",
    "            \n",
    "            journey_id += 1\n",
    "        \n",
    "        # Combine all touchpoints\n",
    "        all_touchpoints = customer_journeys + non_converting_journeys\n",
    "        touchpoints_df = pd.DataFrame(all_touchpoints)\n",
    "        \n",
    "        print(f\"✅ Customer journey data simulated:\")\n",
    "        print(f\"  🎯 {len(set([t['journey_id'] for t in customer_journeys]))} converting journeys\")\n",
    "        print(f\"  📊 {len(set([t['journey_id'] for t in non_converting_journeys]))} non-converting journeys\")\n",
    "        print(f\"  📈 {len(all_touchpoints)} total touchpoints\")\n",
    "        \n",
    "        self.customer_journeys = touchpoints_df\n",
    "        return touchpoints_df\n",
    "    \n",
    "    def build_attribution_models(self):\n",
    "        \"\"\"Build multiple attribution models for comparison\"\"\"\n",
    "        \n",
    "        print(\"\\n🤖 Building attribution models...\")\n",
    "        \n",
    "        journeys_df = self.customer_journeys\n",
    "        \n",
    "        # 1. Rule-based attribution models\n",
    "        attribution_models = {}\n",
    "        \n",
    "        # First-touch attribution\n",
    "        first_touch = journeys_df[journeys_df['touchpoint_number'] == 1].copy()\n",
    "        first_touch_attr = first_touch.groupby('channel').agg({\n",
    "            'conversion_value': 'sum',\n",
    "            'converted': 'sum',\n",
    "            'journey_id': 'nunique'\n",
    "        }).round(2)\n",
    "        first_touch_attr.columns = ['attributed_revenue', 'attributed_conversions', 'attributed_journeys']\n",
    "        attribution_models['first_touch'] = first_touch_attr\n",
    "        \n",
    "        # Last-touch attribution\n",
    "        last_touch = journeys_df.loc[journeys_df.groupby('journey_id')['touchpoint_number'].idxmax()]\n",
    "        last_touch_attr = last_touch.groupby('channel').agg({\n",
    "            'conversion_value': 'sum',\n",
    "            'converted': 'sum',\n",
    "            'journey_id': 'nunique'\n",
    "        }).round(2)\n",
    "        last_touch_attr.columns = ['attributed_revenue', 'attributed_conversions', 'attributed_journeys']\n",
    "        attribution_models['last_touch'] = last_touch_attr\n",
    "        \n",
    "        # Linear attribution (equal credit to all touchpoints)\n",
    "        converting_journeys = journeys_df[journeys_df['converted'] == 1].copy()\n",
    "        journey_lengths = converting_journeys.groupby('journey_id')['touchpoint_number'].max()\n",
    "        converting_journeys = converting_journeys.merge(\n",
    "            journey_lengths.rename('total_touchpoints'), \n",
    "            on='journey_id'\n",
    "        )\n",
    "        converting_journeys['linear_attribution'] = (\n",
    "            converting_journeys['conversion_value'] / converting_journeys['total_touchpoints']\n",
    "        )\n",
    "        \n",
    "        linear_attr = converting_journeys.groupby('channel').agg({\n",
    "            'linear_attribution': 'sum',\n",
    "            'journey_id': 'nunique'\n",
    "        }).round(2)\n",
    "        linear_attr.columns = ['attributed_revenue', 'attributed_journeys']\n",
    "        linear_attr['attributed_conversions'] = linear_attr['attributed_journeys']  # Approximation\n",
    "        attribution_models['linear'] = linear_attr\n",
    "        \n",
    "        # Time-decay attribution (more recent touchpoints get more credit)\n",
    "        converting_journeys['time_decay_weight'] = np.exp(-converting_journeys['days_to_conversion'] / 7)  # 7-day half-life\n",
    "        # Normalize weights within each journey\n",
    "        journey_weight_sums = converting_journeys.groupby('journey_id')['time_decay_weight'].sum()\n",
    "        converting_journeys = converting_journeys.merge(\n",
    "            journey_weight_sums.rename('total_weight'), \n",
    "            on='journey_id'\n",
    "        )\n",
    "        converting_journeys['time_decay_attribution'] = (\n",
    "            converting_journeys['conversion_value'] * \n",
    "            converting_journeys['time_decay_weight'] / converting_journeys['total_weight']\n",
    "        )\n",
    "        \n",
    "        time_decay_attr = converting_journeys.groupby('channel').agg({\n",
    "            'time_decay_attribution': 'sum',\n",
    "            'journey_id': 'nunique'\n",
    "        }).round(2)\n",
    "        time_decay_attr.columns = ['attributed_revenue', 'attributed_journeys']\n",
    "        time_decay_attr['attributed_conversions'] = time_decay_attr['attributed_journeys']\n",
    "        attribution_models['time_decay'] = time_decay_attr\n",
    "        \n",
    "        # 2. Machine Learning Attribution Model\n",
    "        print(\"  🧠 Training ML attribution model...\")\n",
    "        \n",
    "        # Prepare features for ML model\n",
    "        ml_features = journeys_df.copy()\n",
    "        \n",
    "        # Channel encoding\n",
    "        le_channel = LabelEncoder()\n",
    "        ml_features['channel_encoded'] = le_channel.fit_transform(ml_features['channel'])\n",
    "        \n",
    "        # Feature engineering\n",
    "        ml_features['is_first_touch'] = (ml_features['touchpoint_number'] == 1).astype(int)\n",
    "        ml_features['touchpoint_number_log'] = np.log(ml_features['touchpoint_number'])\n",
    "        ml_features['days_to_conversion_log'] = np.log(ml_features['days_to_conversion'].fillna(30) + 1)\n",
    "        ml_features['channel_cost_log'] = np.log(ml_features['channel_cost'] + 0.1)\n",
    "        \n",
    "        # Journey-level features\n",
    "        journey_stats = ml_features.groupby('journey_id').agg({\n",
    "            'touchpoint_number': 'max',\n",
    "            'channel': 'nunique',\n",
    "            'channel_cost': 'sum'\n",
    "        }).rename(columns={\n",
    "            'touchpoint_number': 'journey_length',\n",
    "            'channel': 'unique_channels',\n",
    "            'channel_cost': 'total_journey_cost'\n",
    "        })\n",
    "        \n",
    "        ml_features = ml_features.merge(journey_stats, on='journey_id')\n",
    "        \n",
    "        # Prepare ML dataset\n",
    "        feature_columns = [\n",
    "            'channel_encoded', 'touchpoint_number', 'is_first_touch',\n",
    "            'touchpoint_number_log', 'days_to_conversion_log', 'channel_cost_log',\n",
    "            'journey_length', 'unique_channels', 'total_journey_cost'\n",
    "        ]\n",
    "        \n",
    "        X = ml_features[feature_columns].fillna(0)\n",
    "        y = ml_features['converted']\n",
    "        \n",
    "        # Train model\n",
    "        rf_attribution = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf_attribution.fit(X, y)\n",
    "        \n",
    "        # Predict attribution scores\n",
    "        attribution_scores = rf_attribution.predict_proba(X)[:, 1]\n",
    "        ml_features['ml_attribution_score'] = attribution_scores\n",
    "        \n",
    "        # Calculate ML-based attribution\n",
    "        # Normalize scores within each journey for converting journeys\n",
    "        converting_ml = ml_features[ml_features['converted'] == 1].copy()\n",
    "        journey_score_sums = converting_ml.groupby('journey_id')['ml_attribution_score'].sum()\n",
    "        converting_ml = converting_ml.merge(\n",
    "            journey_score_sums.rename('total_score'), \n",
    "            on='journey_id'\n",
    "        )\n",
    "        converting_ml['ml_attribution'] = (\n",
    "            converting_ml['conversion_value'] * \n",
    "            converting_ml['ml_attribution_score'] / converting_ml['total_score']\n",
    "        )\n",
    "        \n",
    "        ml_attr = converting_ml.groupby('channel').agg({\n",
    "            'ml_attribution': 'sum',\n",
    "            'journey_id': 'nunique'\n",
    "        }).round(2)\n",
    "        ml_attr.columns = ['attributed_revenue', 'attributed_journeys']\n",
    "        ml_attr['attributed_conversions'] = ml_attr['attributed_journeys']\n",
    "        attribution_models['ml_based'] = ml_attr\n",
    "        \n",
    "        # Model performance\n",
    "        auc_score = roc_auc_score(y, attribution_scores)\n",
    "        print(f\"  📈 ML model AUC: {auc_score:.3f}\")\n",
    "        \n",
    "        self.attribution_models = attribution_models\n",
    "        \n",
    "        print(f\"✅ Attribution models built:\")\n",
    "        for model_name in attribution_models.keys():\n",
    "            total_attributed = attribution_models[model_name]['attributed_revenue'].sum()\n",
    "            print(f\"  📊 {model_name.replace('_', ' ').title()}: ${total_attributed:,.0f} attributed revenue\")\n",
    "        \n",
    "        return attribution_models\n",
    "    \n",
    "    def calculate_channel_performance(self):\n",
    "        \"\"\"Calculate comprehensive channel performance metrics\"\"\"\n",
    "        \n",
    "        print(\"\\n📊 Calculating channel performance metrics...\")\n",
    "        \n",
    "        journeys_df = self.customer_journeys\n",
    "        \n",
    "        # Channel-level metrics\n",
    "        channel_metrics = journeys_df.groupby('channel').agg({\n",
    "            'journey_id': 'nunique',\n",
    "            'conversion_value': 'sum',\n",
    "            'converted': 'sum',\n",
    "            'channel_cost': 'sum'\n",
    "        }).round(2)\n",
    "        \n",
    "        channel_metrics.columns = ['total_touchpoints', 'total_revenue', 'total_conversions', 'total_cost']\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        channel_metrics['conversion_rate'] = (\n",
    "            channel_metrics['total_conversions'] / channel_metrics['total_touchpoints']\n",
    "        ).round(4)\n",
    "        \n",
    "        channel_metrics['cost_per_click'] = (\n",
    "            channel_metrics['total_cost'] / channel_metrics['total_touchpoints']\n",
    "        ).round(2)\n",
    "        \n",
    "        channel_metrics['cost_per_conversion'] = (\n",
    "            channel_metrics['total_cost'] / channel_metrics['total_conversions']\n",
    "        ).replace([np.inf, -np.inf], 0).round(2)\n",
    "        \n",
    "        channel_metrics['revenue_per_conversion'] = (\n",
    "            channel_metrics['total_revenue'] / channel_metrics['total_conversions']\n",
    "        ).replace([np.inf, -np.inf], 0).round(2)\n",
    "        \n",
    "        channel_metrics['roas'] = (  # Return on Ad Spend\n",
    "            channel_metrics['total_revenue'] / channel_metrics['total_cost']\n",
    "        ).replace([np.inf, -np.inf], 0).round(2)\n",
    "        \n",
    "        # Set ROAS for free channels (organic, direct, referral) to indicate their value\n",
    "        free_channels = ['organic_search', 'direct', 'referral']\n",
    "        for channel in free_channels:\n",
    "            if channel in channel_metrics.index:\n",
    "                channel_metrics.loc[channel, 'roas'] = 999.99  # Indicate \"infinite\" ROAS\n",
    "        \n",
    "        # Channel attribution comparison across models\n",
    "        attribution_comparison = pd.DataFrame()\n",
    "        for model_name, model_results in self.attribution_models.items():\n",
    "            model_results_copy = model_results.copy()\n",
    "            model_results_copy['model'] = model_name\n",
    "            attribution_comparison = pd.concat([attribution_comparison, model_results_copy.reset_index()])\n",
    "        \n",
    "        # Pivot for easy comparison\n",
    "        attribution_pivot = attribution_comparison.pivot(\n",
    "            index='channel', \n",
    "            columns='model', \n",
    "            values='attributed_revenue'\n",
    "        ).fillna(0).round(0)\n",
    "        \n",
    "        self.channel_performance = {\n",
    "            'metrics': channel_metrics,\n",
    "            'attribution_comparison': attribution_pivot\n",
    "        }\n",
    "        \n",
    "        print(f\"✅ Channel performance calculated:\")\n",
    "        print(f\"  🎯 {len(channel_metrics)} channels analyzed\")\n",
    "        print(f\"  📊 Best ROAS: {channel_metrics['roas'].max():.2f}\")\n",
    "        print(f\"  💰 Total marketing spend: ${channel_metrics['total_cost'].sum():,.0f}\")\n",
    "        \n",
    "        return channel_metrics, attribution_pivot\n",
    "    \n",
    "    def optimize_budget_allocation(self):\n",
    "        \"\"\"Optimize marketing budget allocation using attribution insights\"\"\"\n",
    "        \n",
    "        print(\"\\n💰 Optimizing budget allocation...\")\n",
    "        \n",
    "        channel_metrics = self.channel_performance['metrics']\n",
    "        attribution_comparison = self.channel_performance['attribution_comparison']\n",
    "        \n",
    "        # Current budget allocation (based on current spend)\n",
    "        total_current_spend = channel_metrics['total_cost'].sum()\n",
    "        current_allocation = (channel_metrics['total_cost'] / total_current_spend * 100).round(1)\n",
    "        \n",
    "        # Optimal allocation based on multiple factors\n",
    "        optimization_factors = {}\n",
    "        \n",
    "        for channel in channel_metrics.index:\n",
    "            # Factor 1: ROAS efficiency\n",
    "            roas = channel_metrics.loc[channel, 'roas']\n",
    "            roas_score = min(roas / 5.0, 1.0) if roas < 999 else 1.0  # Normalize, cap at 1.0\n",
    "            \n",
    "            # Factor 2: Attribution consistency (how consistent across models)\n",
    "            channel_attributions = attribution_comparison.loc[channel].values\n",
    "            attribution_std = np.std(channel_attributions) / np.mean(channel_attributions) if np.mean(channel_attributions) > 0 else 1\n",
    "            consistency_score = max(0, 1 - attribution_std)  # Lower std = higher consistency\n",
    "            \n",
    "            # Factor 3: Conversion rate\n",
    "            conv_rate = channel_metrics.loc[channel, 'conversion_rate']\n",
    "            conv_score = min(conv_rate / 0.1, 1.0)  # Normalize with 10% as max\n",
    "            \n",
    "            # Factor 4: Scale potential (inverse of current cost per click)\n",
    "            cpc = channel_metrics.loc[channel, 'cost_per_click']\n",
    "            scale_score = 1 / (1 + cpc / 5.0) if cpc > 0 else 1.0  # Lower CPC = more scalable\n",
    "            \n",
    "            # Combined optimization score\n",
    "            optimization_score = (\n",
    "                roas_score * 0.40 +\n",
    "                consistency_score * 0.25 +\n",
    "                conv_score * 0.20 +\n",
    "                scale_score * 0.15\n",
    "            )\n",
    "            \n",
    "            optimization_factors[channel] = {\n",
    "                'roas_score': roas_score,\n",
    "                'consistency_score': consistency_score,\n",
    "                'conversion_score': conv_score,\n",
    "                'scale_score': scale_score,\n",
    "                'optimization_score': optimization_score,\n",
    "                'current_allocation': current_allocation.get(channel, 0),\n",
    "                'current_spend': channel_metrics.loc[channel, 'total_cost']\n",
    "            }\n",
    "        \n",
    "        # Calculate optimal allocation\n",
    "        total_optimization_score = sum([factors['optimization_score'] for factors in optimization_factors.values()])\n",
    "        \n",
    "        # Proposed budget allocation\n",
    "        proposed_budget = 100000  # Assume $100K total budget\n",
    "        \n",
    "        budget_recommendations = []\n",
    "        for channel, factors in optimization_factors.items():\n",
    "            optimal_allocation = factors['optimization_score'] / total_optimization_score * 100\n",
    "            optimal_budget = proposed_budget * optimal_allocation / 100\n",
    "            \n",
    "            current_budget = factors['current_spend']\n",
    "            budget_change = optimal_budget - current_budget\n",
    "            budget_change_pct = (budget_change / current_budget * 100) if current_budget > 0 else 0\n",
    "            \n",
    "            # Expected impact\n",
    "            current_roas = channel_metrics.loc[channel, 'roas']\n",
    "            expected_revenue_impact = budget_change * (current_roas if current_roas < 999 else 5.0)\n",
    "            \n",
    "            budget_recommendations.append({\n",
    "                'channel': channel,\n",
    "                'current_allocation_pct': factors['current_allocation'],\n",
    "                'current_budget': current_budget,\n",
    "                'optimal_allocation_pct': optimal_allocation,\n",
    "                'optimal_budget': optimal_budget,\n",
    "                'budget_change': budget_change,\n",
    "                'budget_change_pct': budget_change_pct,\n",
    "                'optimization_score': factors['optimization_score'],\n",
    "                'expected_revenue_impact': expected_revenue_impact,\n",
    "                'recommendation': self._get_budget_recommendation(budget_change_pct, factors['optimization_score'])\n",
    "            })\n",
    "        \n",
    "        budget_df = pd.DataFrame(budget_recommendations)\n",
    "        budget_df = budget_df.sort_values('optimization_score', ascending=False)\n",
    "        \n",
    "        print(f\"✅ Budget optimization completed:\")\n",
    "        print(f\"  💰 Total budget optimized: ${proposed_budget:,}\")\n",
    "        \n",
    "        # Display top recommendations\n",
    "        print(f\"\\n🎯 TOP BUDGET RECOMMENDATIONS:\")\n",
    "        for i, (_, rec) in enumerate(budget_df.head(3).iterrows(), 1):\n",
    "            print(f\"  {i}. {rec['channel'].replace('_', ' ').title()}\")\n",
    "            print(f\"     📊 Change: {rec['budget_change_pct']:+.0f}% (${rec['budget_change']:+,.0f})\")\n",
    "            print(f\"     💰 Expected impact: ${rec['expected_revenue_impact']:+,.0f}\")\n",
    "            print(f\"     💡 {rec['recommendation']}\")\n",
    "        \n",
    "        return budget_df\n",
    "    \n",
    "    def _get_budget_recommendation(self, change_pct, optimization_score):\n",
    "        \"\"\"Generate budget recommendation based on metrics\"\"\"\n",
    "        if change_pct > 50 and optimization_score > 0.7:\n",
    "            return \"Significantly increase investment - high ROI potential\"\n",
    "        elif change_pct > 20 and optimization_score > 0.5:\n",
    "            return \"Increase investment - good performance\"\n",
    "        elif abs(change_pct) < 20:\n",
    "            return \"Maintain current investment level\"\n",
    "        elif change_pct < -20 and optimization_score < 0.3:\n",
    "            return \"Reduce investment - poor performance\"\n",
    "        else:\n",
    "            return \"Monitor closely - mixed signals\"\n",
    "    \n",
    "    def create_attribution_summary(self):\n",
    "        \"\"\"Create a comprehensive summary of attribution analysis\"\"\"\n",
    "        \n",
    "        print(\"\\n📊 Creating attribution analysis summary...\")\n",
    "        \n",
    "        attribution_comparison = self.channel_performance['attribution_comparison']\n",
    "        channel_metrics = self.channel_performance['metrics']\n",
    "        \n",
    "        summary = {\n",
    "            'total_revenue': self.transaction_data['total_amount'].sum(),\n",
    "            'total_transactions': len(self.transaction_data),\n",
    "            'total_touchpoints': len(self.customer_journeys),\n",
    "            'avg_journey_length': self.customer_journeys.groupby('journey_id')['touchpoint_number'].max().mean(),\n",
    "            'conversion_rate': self.customer_journeys['converted'].mean(),\n",
    "            'top_performing_channel': channel_metrics['roas'].idxmax(),\n",
    "            'best_roas': channel_metrics['roas'].max(),\n",
    "            'total_marketing_spend': channel_metrics['total_cost'].sum(),\n",
    "            'overall_roas': channel_metrics['total_revenue'].sum() / channel_metrics['total_cost'].sum()\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Create sample data for attribution analysis\n",
    "def create_attribution_sample_data():\n",
    "    \"\"\"Create sample e-commerce data for marketing attribution\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    n_transactions = 5000\n",
    "    \n",
    "    # Create date range with proper datetime objects\n",
    "    date_range = pd.date_range(start='2024-01-01', periods=n_transactions, freq='4H')\n",
    "    \n",
    "    data = {\n",
    "        'transaction_id': range(1, n_transactions + 1),\n",
    "        'customer_id': np.random.randint(1, 3500, n_transactions),\n",
    "        'date': date_range,\n",
    "        'category': np.random.choice(['Electronics', 'Clothing', 'Books', 'Home', 'Sports'], n_transactions),\n",
    "        'total_amount': np.random.lognormal(3.5, 0.7, n_transactions),\n",
    "        'rating': np.random.choice([1, 2, 3, 4, 5], n_transactions, p=[0.02, 0.08, 0.20, 0.45, 0.25]),\n",
    "        'device': np.random.choice(['Mobile', 'Desktop', 'Tablet'], n_transactions, p=[0.68, 0.28, 0.04]),\n",
    "        'region': np.random.choice(['North America', 'Europe', 'Asia', 'Others'], n_transactions)\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Initialize attribution analysis\n",
    "print(\"📊 Creating sample data for attribution analysis...\")\n",
    "transaction_data = create_attribution_sample_data()\n",
    "print(f\"✅ Transaction data: {len(transaction_data)} purchases, ${transaction_data['total_amount'].sum():,.0f} revenue\")\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = MarketingAttributionAnalyzer(transaction_data)\n",
    "\n",
    "# Run complete attribution analysis\n",
    "print(\"\\n🚀 Starting marketing attribution analysis...\")\n",
    "\n",
    "try:\n",
    "    # 1. Simulate customer journeys\n",
    "    customer_journeys = analyzer.simulate_customer_journeys()\n",
    "\n",
    "    # 2. Build attribution models\n",
    "    attribution_models = analyzer.build_attribution_models()\n",
    "\n",
    "    # 3. Calculate channel performance\n",
    "    channel_performance, attribution_comparison = analyzer.calculate_channel_performance()\n",
    "\n",
    "    # 4. Optimize budget allocation\n",
    "    budget_optimization = analyzer.optimize_budget_allocation()\n",
    "\n",
    "    # 5. Create summary\n",
    "    attribution_summary = analyzer.create_attribution_summary()\n",
    "\n",
    "    print(f\"\\n✅ Marketing attribution analysis completed!\")\n",
    "    print(f\"🎯 {len(customer_journeys)} customer touchpoints analyzed\")\n",
    "    print(f\"📊 {len(attribution_models)} attribution models compared\")\n",
    "    print(f\"💰 Overall ROAS: {attribution_summary['overall_roas']:.2f}x\")\n",
    "    print(f\"🏆 Best performing channel: {attribution_summary['top_performing_channel'].replace('_', ' ').title()}\")\n",
    "\n",
    "    # Display key metrics\n",
    "    print(f\"\\n📈 ATTRIBUTION MODEL COMPARISON:\")\n",
    "    total_revenues = attribution_comparison.sum()\n",
    "    for model, revenue in total_revenues.items():\n",
    "        print(f\"  📊 {model.replace('_', ' ').title()}: ${revenue:,.0f}\")\n",
    "\n",
    "    print(f\"\\n🎯 TOP CHANNEL PERFORMANCE:\")\n",
    "    channel_performance_sorted = channel_performance.sort_values('roas', ascending=False)\n",
    "    for i, (channel, metrics) in enumerate(channel_performance_sorted.head(5).iterrows(), 1):\n",
    "        roas_display = f\"{metrics['roas']:.1f}x\" if metrics['roas'] < 999 else \"∞\"\n",
    "        print(f\"  {i}. {channel.replace('_', ' ').title()}: {roas_display} ROAS, {metrics['conversion_rate']:.1%} conversion\")\n",
    "        \n",
    "    # Display budget recommendations\n",
    "    print(f\"\\n💰 BUDGET OPTIMIZATION SUMMARY:\")\n",
    "    for i, (_, rec) in enumerate(budget_optimization.head(3).iterrows(), 1):\n",
    "        print(f\"  {i}. {rec['channel'].replace('_', ' ').title()}: {rec['budget_change_pct']:+.0f}% change recommended\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error in analysis: {str(e)}\")\n",
    "    print(\"Please check the data and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8284f9a-de05-4ece-a245-c612b9369383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
